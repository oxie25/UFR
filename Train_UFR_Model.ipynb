{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This workbook is used for training UFR models on infinite dilution activity coefficients (IDAC)\n",
    "\n",
    "**Oliver Xie - Olsen Lab, Massachusetts Institute of Technology, 2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import torch\n",
    "import warnings\n",
    "import ufr.model.idac_model as idac_model\n",
    "import ufr.util.data_processing as data_processing\n",
    "import ufr.util.model_launch as model_launch\n",
    "\n",
    "# Disable prototype warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "# Disable future deprecation warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Specify to use a specific GPU device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Two files are required, one containing the IDAC data (data_file) and another containing the small molecule properties (prop_file). Each should be loaded as a pandas DataFrame.\n",
    "\n",
    "The IDAC data should have each unique IDAC entry be its own row. Columns should be named as follows and contain:\n",
    "1) 'Solute': The name of the solute molecule\n",
    "2) 'Solvent': The name of the solvent molecule\n",
    "3) 'Solute SMILES': The canonical SMILES name of the solute molecule\n",
    "4) 'Solvent SMILES': The canonical SMILES name of the solvent molecule\n",
    "5) 'Temp (K)': The temperature of the measurement in Kelvin\n",
    "6) 'ln gamma': The IDAC measurement reported as ln $\\gamma^\\infty_i$\n",
    "\n",
    "The small molecule properties file should contain a unique chemical in each row. Columns should be named as follows and contain:\n",
    "1) 'IUPAC Name': The IUPAC name of the molecule\n",
    "2) 'Canonical SMILES': The canonical SMILES name of the molecule\n",
    "3) 'van der waals volume (m3/kmol)': The van der Waals volume of each molecule in m3/kmol. Water has a modified van der Waals volume reflecting the value used in UNIQUAC.\n",
    "4) 'van der waals area (m2/kmol)': The van der Waals surface area of each molecule in m2/kmol. Water has a modified van der Waals volume reflecting the value used in UNIQUAC.\n",
    "5) 'H donor sites': The number of hydrogen bond donor sites per molecule as calculated using RDKit Lipinski module\n",
    "6) 'H acceptor sites': The number of hydrogen bond acceptor sites per molecule as calculated using RDKit Lipinski module\n",
    "\n",
    "There are 5 additional columns ('A', 'B', 'C', 'D', 'Eqn') that are required for calculating the free volume of each molecule using the DIPPR Project 801 correlations for molar volume with temperature. As this data cannot be freely distributed, all entries are left blank. These columns are required for any combinatorial layer choice that requires free volume (Elbro-FV, mod-FV, GK-FV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the data file\n",
    "data_file = \"./data/opensource_IDAC_data.csv\"\n",
    "prop_file = \"./data/small_molecule_prop.csv\"\n",
    "\n",
    "df_inf = pd.read_csv(data_file, index_col = 0)\n",
    "df_prop = pd.read_csv(prop_file, index_col = 0)\n",
    "\n",
    "solute_smiles = 'Solute SMILES' # Specify the column name in df_inf\n",
    "solvent_smiles = 'Solvent SMILES' # Specify the column name in df_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Processing\n",
    "\n",
    "Several steps are used to clean the data (if desired). Experimental IDAC data is inherently noisy and contains errors. Cleaning out significant outliers is necessary to train the UFRs on real relationships rather than wrong ones induced by the data.\n",
    "\n",
    "The data cleaning steps include:\n",
    "1) Change all D2O entries to have a unique SMILES that is not the same as water's.\n",
    "2) Filter out duplicate entries, keeping only one copy. Duplicates defined as having the exact same solute, solvent, temperature and IDAC value.\n",
    "3) Remove any self-edges (solute and solvent are the same)\n",
    "4) Clean data according to cleaning rules (optional). Load and use attached cleaning rules.\n",
    "5) Remove outliers from lines of best fit with inverse temperature. For aqueous mixtures use a quadratic polynomial fit and for non-aqueous mixtures use a linear fit with inverse temperature. For a given mixture, outliers are classified as points with absolute residuals more than 3 times greater than the standard deviation of the residuals. Only do this filtering on mixtures containing more than 5 points at 4 unique temperatures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certain datasets report deuterated water but RDKit converts it to water. There are slight differences in IDAC for D2O. Manually convert these to a different SMILES name.\n",
    "deuterated_water = 'Deuterium oxide <Heavy water>'\n",
    "df_inf.loc[df_inf['Solute'] == deuterated_water, solute_smiles] = '[2H]O[2H]'\n",
    "df_inf.loc[df_inf['Solvent'] == deuterated_water, solvent_smiles] = '[2H]O[2H]'\n",
    "\n",
    "# Filter out duplicates and drop self-edges\n",
    "self_edges = df_inf[df_inf[solute_smiles] == df_inf[solvent_smiles]].index\n",
    "df_inf = df_inf.drop(self_edges)\n",
    "\n",
    "# Drop duplicates\n",
    "df_inf_no_duplicates = data_processing.drop_duplicates(df_inf)\n",
    "\n",
    "# Set flag on whether to clean the data or not\n",
    "clean_temp_outliers = True # False or True\n",
    "\n",
    "# If True, clean the data\n",
    "if clean_temp_outliers:\n",
    "    # Load the cleaning rules\n",
    "    cleaning_rules_file = './data/cleaning_rules.xlsx'\n",
    "    df_clean_rules = pd.read_excel(cleaning_rules_file, sheet_name = 'cleaning rules')\n",
    "\n",
    "    # Clean according to the cleaning rules\n",
    "    df_inf_no_duplicates = data_processing.apply_cleaning(df_inf_no_duplicates, df_clean_rules)\n",
    "\n",
    "    # Drop all outliers. Can specify how many times away from the standard deviation to consider an outlier (default 3)\n",
    "    df_inf_clean, df_dropped = data_processing.remove_temperature_outliers(df_inf_no_duplicates, std_dev = 3) # df_dropped is what were dropped\n",
    "\n",
    "else:\n",
    "    df_inf_clean = df_inf_no_duplicates.copy()\n",
    "\n",
    "print(f'We now have {df_inf_clean.shape[0]} rows in the dataset from the original {df_inf.shape[0]} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the df_prop DataFrame to get the required small molecule properties for each solute and solvent. Enter it into the df_inf_clean DataFrame. There are two modes for the addition, 'FH' for all combinatorial models that do not require free volume, and 'FV' for all combinatorial models that do.\n",
    "\n",
    "Because the combinatorial term does not require any regressed parameters, it is directly calculated in molecular_property_addition and stored in df_inf_regress. The Pytorch UFR models train against the remaining activity coefficient after subtraction of the combinatorial term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inf_regress, v0, s0 = data_processing.molecular_property_addition(df_inf_clean, df_prop, mode = 'FH', solute_smiles = solute_smiles, solvent_smiles = solvent_smiles) # The mode can be changed between 'FH' and 'FV'. Note: 'FV' requires the DIPPR correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the UFR model\n",
    "\n",
    "The UFR models can now be trained. The following model choices need to be specified.\n",
    "\n",
    "1) Dimensions: The total number of dimensions to use for each node's (chemical) thermodynamic embedding. This is $N_{embedding}$ as specified in the paper. Depending on the model chosen, different parts of the embedding may be reserved for different model layers.\n",
    "2) Trials: How many trials of each model to run. Each trial number serves as the seed for the random number generator, ensuring different initial conditions each time.\n",
    "3) Combinatorial model: The choice of combinatorial layer to use specifies which column of df_inf_regress to gather $\\ln{\\gamma}^{\\infty}$ from. The combinatorial contribution is calculated for every model and subtracted from the data. \n",
    "    - Choices without free volume include: FH (Flory-Huggins), mod-FH (2/3 modified Flory-Huggins), SG (Staverman-Guggenheim)\n",
    "    - Choices with free volume include FV (Elbro free volume), mod-FV (2/3 modified Elbro free volume), GK-FV (Staverman-Guggenheim with free volume)\n",
    "4) Residual model: The choice of the residual layer as described in the main text\n",
    "    - Choices include: UNIQUAC, mod-UNIQUAC, Wilson, NRTL\n",
    "5) Association model: The choice of the association layer as described in the main text\n",
    "    - Choices include: None, Wertheim\n",
    "6) Temperature layer: The exponents for the temperature dependence must be specified. We work with inverse temperature, so the exponents correspond to that for inverse temperature.\n",
    "6) Sobolev loss: To penalize for incorrect temperature correlations, the Sobolev loss can be turned on. In the paper, the parameter weighting the Sobolev loss was studied at 0.2 and 1.\n",
    "7) Hyperparameters: Learning rate. Total number of epochs and number of epochs for ramping up, holding, and ramping down the learning rate. The number of epochs to separately regress the residual and association layers (if both are used); keep this number low (~500)\n",
    "8) Truncation mode: For data truncation to prevent overfitting, the graph of interconnected IDACs are recursively checked until no more truncations occur. This can be turned on or off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a model savepath\n",
    "save_path = './trained_models/'\n",
    "\n",
    "# Set the desired dimensionality of the thermodynamic embedding. This affects how much data is truncated. If set too high, a lot of the data will be truncated.\n",
    "dimension = 6\n",
    "\n",
    "# Set number of trials to run. This number serves as the seed to the random number generator.\n",
    "trials = 1\n",
    "\n",
    "# Specify parts of the model\n",
    "combinatorial_layer = 'mod_FH' # Choose between FH, FV, SG, GK-FV, mod_FH, mod_FV\n",
    "residual_layer = 'mod_UNIQUAC' # Choose between UNIQUAC, mod_UNIQUAC, Wilson, NRTL\n",
    "association_layer = 'wertheim' # Choose between none, wertheim\n",
    "\n",
    "# Temperature layer - Always go from smallest to largest. These are powers and correspond to inverse temperature\n",
    "# To use the Taylor series expansion in temperature, negative exponents are needed. Due to the division by T, there will always be a 1/T component\n",
    "# The choices investigated in the model include:\n",
    "# Original dependence (original UNIFAC, Wilson, NRTL dependence) : [1]\n",
    "# First-degree expansion (either in 1/T or T): [0, 1]\n",
    "# Second-degree expansion in 1/T: [0, 1, 2]\n",
    "# Second-degree expansion in T: [-1, 0, 1]\n",
    "temp_type = 'invT' # Specify whether the expansion is in invT or T. This is just for the model filename\n",
    "temp_exponents = np.array([0, 1], dtype = float) # Must set as numpy array and as float\n",
    "\n",
    "# Sobolev loss\n",
    "sobolev = 0 # 0 turns this off. Any non-zero value turns on the Sobolev loss and becomes the weight for the term.\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.01 # Learning rate\n",
    "total_epochs = 30000 # Total number of epochs to run\n",
    "up_epochs = 1000 # Number of epochs for ramping up the model\n",
    "hold_epochs = 20000 # Number of epochs for holding at the maximum learning rate\n",
    "pre_train_epoch = 500 # Number of epochs for separately regressing the residual and association layers if both are used.\n",
    "\n",
    "# Truncation to prevent overfitting\n",
    "truncation = 'chemical_connections' # Set to temp_connections if we want to count each pairing's temperature as unique. Set to chemical_connections if we want to count each pairing's temperature as one entry. Set to 'keep_all' if we don't want it to truncate\n",
    "\n",
    "# Set up a savename for the model\n",
    "model_name = f'UFR_{combinatorial_layer}_{residual_layer}_{association_layer}_{dimension}D_{temp_type}_{temp_exponents.size}_sobolev_{sobolev}'\n",
    "save_name = save_path + model_name\n",
    "\n",
    "# Set up dictionaries of model parameters for passing into the model\n",
    "ln_y_data = f'ln_gamma_res_{combinatorial_layer}' # This specifies which IDAC with combinatorial removed to regress on.\n",
    "model_layer_options = {'ln_y_data': ln_y_data, 'combinatorial_layer': combinatorial_layer, 'residual_layer': residual_layer, 'association_layer': association_layer, 'temp_exponents': temp_exponents, 'reference_volume': v0, 'reference_area': s0}\n",
    "model_opt_options = {'sobolev': sobolev, 'lr': lr, 'total_epochs': total_epochs, 'up_epochs': up_epochs, 'hold_epochs': hold_epochs}\n",
    "model_run_options = {'truncation': truncation, 'smile_labels' : (solute_smiles, solvent_smiles), 'pre_train_epoch': pre_train_epoch, 'save_name': save_name}\n",
    "\n",
    "# We need to calculate the gradient if we are using Sobolev loss. This is done in the invtemp_gradient_calc function.\n",
    "# We can specify what solute-solvent pairs to consider in the calculation\n",
    "if sobolev > 0:\n",
    "    print('Starting calculation for Sobolev regularization, this might take a while')\n",
    "    df_inf_regress = data_processing.invtemp_gradient_calc(df_inf_regress, ln_y_data, min_points = 4, min_delta_T = 30, std_residuals_tol = 0.1, rel_std_residuals_tol = 0.1)\n",
    "\n",
    "# Launch the model\n",
    "model_launch.launch_model(dimension, trials, df_inf_regress.copy(), df_prop.copy(), model_layer_options, model_opt_options, model_run_options, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
